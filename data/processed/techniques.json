{
  "categories": [
    {
      "id": "basic-concepts",
      "name": "Basic Concepts",
      "description": "Fundamental prompting structures and conceptual frameworks",
      "techniques": [
        {
          "id": "basic-prompting",
          "name": "Basic Prompting",
          "aliases": ["Standard Prompting", "Vanilla Prompting"],
          "description": "The simplest form of prompting, usually consisting of an instruction and input, without exemplars or complex reasoning steps.",
          "sources": ["Vatsal & Dubey", "Schulhoff et al.", "Wei et al."],
          "relatedTechniques": ["instructed-prompting", "zero-shot-learning"],
          "useCase": "Simple, direct tasks where clarity is paramount. Effective for well-defined tasks with clear instructions.",
          "example": "Translate the following English text to French: 'Hello, how are you?'"
        },
        {
          "id": "few-shot-learning",
          "name": "Few-Shot Learning/Prompting",
          "description": "Providing K > 1 demonstrations in the prompt to help the model understand patterns.",
          "sources": ["Brown et al.", "Wei et al.", "Schulhoff et al."],
          "relatedTechniques": ["one-shot-learning", "zero-shot-learning", "in-context-learning"],
          "useCase": "Tasks where examples help illustrate the desired pattern or format of response.",
          "example": "Classify the sentiment of the following restaurant reviews as positive or negative:\n\nExample 1: 'The food was delicious.' Sentiment: positive\nExample 2: 'Terrible service and cold food.' Sentiment: negative\n\nNew review: 'The atmosphere was nice but waiting time was too long.'"
        },
        {
          "id": "zero-shot-learning",
          "name": "Zero-Shot Learning/Prompting",
          "description": "Prompting with instruction only, without any demonstrations or examples.",
          "sources": ["Brown et al.", "Vatsal & Dubey", "Schulhoff et al."],
          "relatedTechniques": ["few-shot-learning", "one-shot-learning", "instructed-prompting"],
          "useCase": "Simple tasks or when working with capable models that don't require examples.",
          "example": "Summarize the main points of the following article in 3 bullet points: [article text]"
        },
        {
          "id": "one-shot-learning",
          "name": "One-Shot Learning/Prompting",
          "description": "Providing exactly one demonstration in the prompt to help the model understand patterns.",
          "sources": ["Brown et al.", "Schulhoff et al."],
          "relatedTechniques": ["few-shot-learning", "zero-shot-learning", "in-context-learning"],
          "useCase": "When a single example sufficiently conveys the pattern or when context length is limited.",
          "example": "Translate English to French:\nEnglish: The weather is beautiful today.\nFrench: Le temps est beau aujourd'hui.\n\nEnglish: I would like to order dinner."
        },
        {
          "id": "in-context-learning",
          "name": "In-Context Learning (ICL)",
          "description": "The model's ability to learn from demonstrations/instructions within the prompt at inference time, without updating weights.",
          "sources": ["Brown et al.", "Schulhoff et al."],
          "relatedTechniques": ["few-shot-learning", "exemplar-selection", "exemplar-ordering"],
          "useCase": "Achieving task-specific behavior without fine-tuning, particularly effective for classification, translation, and reasoning tasks.",
          "example": "Q: What is the capital of France?\nA: Paris\n\nQ: What is the capital of Japan?\nA: Tokyo\n\nQ: What is the capital of Australia?\nA:"
        },
        {
          "id": "cloze-prompts",
          "name": "Cloze Prompts",
          "description": "Prompts with masked slots for prediction, often in the middle of the text.",
          "sources": ["Wang et al. - Healthcare Survey", "Schulhoff et al."],
          "relatedTechniques": ["prefix-prompts", "fill-in-the-blank-format"],
          "useCase": "Extractive QA, knowledge probing, and logical completion tasks.",
          "example": "The capital of France is _____."
        },
        {
          "id": "prefix-prompts",
          "name": "Prefix Prompts",
          "description": "Standard prompt format where the prediction follows the input.",
          "sources": ["Wang et al. - Healthcare Survey", "Schulhoff et al."],
          "relatedTechniques": ["cloze-prompts", "continuous-prompt"],
          "useCase": "Most general-purpose prompting scenarios where text completion is desired.",
          "example": "Write a short poem about autumn:"
        },
        {
          "id": "template-prompting",
          "name": "Templating (Prompting)",
          "description": "Using functions with variable slots to construct prompts in a systematic way.",
          "sources": ["Schulhoff et al."],
          "relatedTechniques": ["basic-prompting", "instruction-selection"],
          "useCase": "When standardizing prompts across multiple inputs or creating programmatic interfaces.",
          "example": "def generate_summary_prompt(text):\n    return f\"Summarize the following text in 3 sentences:\\n\\n{text}\""
        },
        {
          "id": "instructed-prompting",
          "name": "Instructed Prompting",
          "description": "Explicitly instructing the LLM with clear directions about the task.",
          "sources": ["Vatsal & Dubey"],
          "relatedTechniques": ["basic-prompting", "zero-shot-learning"],
          "useCase": "Any task where specific behavioral guidance is needed.",
          "example": "You are a professional translator. Translate the following English text to Spanish, maintaining the same tone and formality level:"
        }
      ]
    },
    {
      "id": "reasoning-frameworks",
      "name": "Reasoning Frameworks",
      "description": "Techniques that guide the model through explicit reasoning steps",
      "techniques": [
        {
          "id": "chain-of-thought",
          "name": "Chain-of-Thought (CoT) Prompting",
          "description": "Eliciting step-by-step reasoning before the final answer, usually via few-shot exemplars.",
          "sources": ["Wei et al.", "Schulhoff et al.", "Vatsal & Dubey", "Wang et al. - Self-Consistency"],
          "relatedTechniques": ["zero-shot-cot", "few-shot-cot", "self-consistency"],
          "useCase": "Complex reasoning tasks, math problems, logical deductions, and multi-step decision processes.",
          "example": "Question: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?\n\nLet's think about this step-by-step:\n1. Roger starts with 5 tennis balls\n2. He buys 2 cans of tennis balls, with 3 balls per can\n3. So he gets 2 × 3 = 6 new tennis balls\n4. In total, he has 5 + 6 = 11 tennis balls\n\nAnswer: 11 tennis balls"
        },
        {
          "id": "zero-shot-cot",
          "name": "Zero-Shot CoT",
          "description": "Appending a thought-inducing phrase without CoT exemplars, like 'Let's think step by step'.",
          "sources": ["Schulhoff et al.", "Vatsal & Dubey"],
          "relatedTechniques": ["chain-of-thought", "few-shot-cot"],
          "useCase": "When example chains of reasoning aren't available but step-by-step thinking is still beneficial.",
          "example": "Question: If a store has 10 apples and 3 people each buy 2 apples, how many apples are left?\n\nLet's think step by step."
        },
        {
          "id": "few-shot-cot",
          "name": "Few-Shot CoT",
          "description": "CoT prompting using multiple CoT exemplars to demonstrate the reasoning process.",
          "sources": ["Schulhoff et al.", "Vatsal & Dubey"],
          "relatedTechniques": ["chain-of-thought", "zero-shot-cot"],
          "useCase": "Complex reasoning tasks where the model needs to learn specific reasoning patterns.",
          "example": "Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?\nA: Roger starts with 5 tennis balls. He buys 2 cans, each with 3 tennis balls. So he gets 2×3=6 more tennis balls. In total, he has 5+6=11 tennis balls.\n\nQ: Alice has 7 books. She gives 2 books to Bob and buys 3 more books. How many books does she have now?"
        },
        {
          "id": "tree-of-thoughts",
          "name": "Tree-of-Thoughts (ToT)",
          "description": "Exploring multiple reasoning paths in a tree structure using generate, evaluate, and search methods.",
          "sources": ["Yao et al.", "Vatsal & Dubey", "Schulhoff et al."],
          "relatedTechniques": ["chain-of-thought", "graph-of-thoughts", "self-consistency"],
          "useCase": "Complex problems with multiple possible approaches, where exploring alternatives is beneficial.",
          "example": "Problem: Find the optimal strategy for the game of 24 (reach 24 using +, -, *, / with cards 3, 9, 4, 1).\n\nPath 1: (3 + 9) * (4 - 1) = 12 * 3 = 36 (invalid)\nPath 2: (3 * 9 - 4) - 1 = 27 - 4 - 1 = 22 (invalid)\nPath 3: (3 + 1) * 9 - 4 = 4 * 9 - 4 = 36 - 4 = 32 (invalid)\nPath 4: 3 * (9 - 1) - 4 = 3 * 8 - 4 = 24 - 4 = 20 (invalid)\nPath 5: (9 - 1) * (4 - 3) = 8 * 1 = 8 (invalid)\nPath 6: 3 * 9 - 4 - 1 = 27 - 4 - 1 = 22 (invalid)\nPath 7: 3 * (9 - 4) + 1 = 3 * 5 + 1 = 15 + 1 = 16 (invalid)\nPath 8: (3 + 9) * 4 / (1 + 3) = 12 * 4 / 4 = 12 (invalid)\nPath 9: 9 * 4 / 3 + 1 = 36 / 3 + 1 = 12 + 1 = 13 (invalid)\nPath 10: (9 - 1) * 3 = 8 * 3 = 24 (valid!)"
        },
        {
          "id": "skeleton-of-thought",
          "name": "Skeleton-of-Thought (SoT)",
          "description": "A two-stage approach: first generating a skeleton (outline) and then expanding points in parallel.",
          "sources": ["Ning et al.", "Schulhoff et al."],
          "relatedTechniques": ["tree-of-thoughts", "parallel-point-expanding"],
          "useCase": "Long-form content generation where structure is important, like essays or reports.",
          "example": "Task: Write an essay about climate change.\n\nSkeleton:\n1. Introduction to climate change\n2. Causes of climate change\n3. Effects on ecosystems\n4. Economic impacts\n5. Potential solutions\n6. Conclusion\n\n[Then each point is expanded in parallel]"
        }
      ]
    }
  ]
}